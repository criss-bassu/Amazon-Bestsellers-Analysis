# ðŸ“˜ PySpark Amazon Bestsellers Analysis

This repository contains the solution to a data processing assignment using Apache Spark. The goal is to demonstrate practical knowledge in building data processing pipelines and utilizing PySpark for analyzing large datasets.

## ðŸ“š Assignment Overview

**Dataset:** `AmazonBooks-1.csv`  
**Notebook:** `PySpark_Assignment_Feb25.ipynb`  
**Scope:** Analysis of the Top 50 Amazon bestselling books from 2009 to 2019 using PySpark.

## ðŸŽ¯ Learning Outcomes

This project satisfies the following learning outcomes:

- âœ… Ability to write data processing pipelines using Apache Spark
- âœ… Understanding of how Apache Spark handles and processes data

## ðŸ§ª Exercises

- **Exercise 1 (5 Marks):** Identify authors with the most entries in the bestsellers list. For each, calculate:
  - Number of unique titles
  - Average rating
  - Total number of reviews
  - Highest rank achieved

- **Exercise 2 (5 Marks):** For fiction and non-fiction books, compute the average and total reviews for the top 10, 25, and 50 bestsellers per year.

- **Exercise 3 (10 Marks):** Calculate the average price of fiction and non-fiction books in the top 10, 25, and 50 bestsellers per year.

- **Exercise 4 (10 Marks):** Analyze free books (price = 0):
  - Count unique titles and authors
  - Compare average ratings and number of reviews per year with priced books

## ðŸ›  Technologies Used

- Apache Spark (PySpark)
- Google Colab
- Python
- CSV Data Processing

## ðŸš€ Usage

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/pyspark-amazon-bestsellers.git
   cd pyspark-amazon-bestsellers
